{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RFormula\n",
    "from pyspark.ml.classification import RandomForestClassifier as sparkRFClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier as sklearnRFClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Spark Context and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv',\n",
       " 'train-0.001m.csv',\n",
       " 'train-0.01m.csv',\n",
       " 'train-0.1m.csv',\n",
       " 'train-1.0m.csv',\n",
       " 'train-10.0m.csv',\n",
       " 'valid.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../air_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+-------+-------------+------+----+--------+-----------------+\n",
      "|Month|DayofMonth|DayOfWeek|DepTime|UniqueCarrier|Origin|Dest|Distance|dep_delayed_15min|\n",
      "+-----+----------+---------+-------+-------------+------+----+--------+-----------------+\n",
      "| c-10|      c-25|      c-3|    840|           B6|   IAD| BOS|     413|                N|\n",
      "| c-12|      c-13|      c-3|    853|           UA|   LAX| KOA|    2504|                N|\n",
      "|  c-9|       c-5|      c-2|   1541|           OH|   SAT| CVG|    1024|                N|\n",
      "|  c-5|      c-12|      c-4|   1812|           F9|   DEN| LAX|     862|                Y|\n",
      "|  c-5|      c-30|      c-2|   1028|           WN|   PIT| LAS|    1910|                N|\n",
      "|  c-5|      c-31|      c-2|   2254|           OH|   CVG| DTW|     229|                N|\n",
      "|  c-4|       c-8|      c-5|   1807|           XE|   IAD| EWR|     213|                Y|\n",
      "|  c-1|      c-27|      c-5|   1608|           YV|   CLT| ROC|     573|                N|\n",
      "|  c-6|      c-28|      c-3|   1337|           UA|   PDX| LAX|     834|                N|\n",
      "|  c-9|      c-27|      c-3|   1604|           DL|   ATL| CMH|     446|                N|\n",
      "+-----+----------+---------+-------+-------------+------+----+--------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_raw = spark.read.csv('../air_example/train-0.001m.csv', header = True, inferSchema=True)\n",
    "train_raw.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|dep_delayed_15min|count|\n",
      "+-----------------+-----+\n",
      "|                Y|  219|\n",
      "|                N|  781|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_raw.groupby('dep_delayed_15min').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to some Java/Python bug in this Docker container, for 100K+ datasets need to go through Pandas (#facepalm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_spark_df(n=None):\n",
    "    file_name = 'test' if n is None else 'train-' + str(n/1e6) + 'm'\n",
    "    pd_df = pd.read_csv('../air_example/' + file_name + '.csv', header = 0)\n",
    "    spark_df = spark.createDataFrame(pd_df)\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = get_data_spark_df(1000)\n",
    "train_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw = get_data_spark_df()\n",
    "test_raw.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data ready for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = RFormula(formula='dep_delayed_15min ~ .', featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_for_spark_rf(train, test):\n",
    "    train_test = train.union(test)\n",
    "    formula_fit = formula.fit(train_test)\n",
    "    train_df = formula_fit.transform(train)\n",
    "    test_df = formula_fit.transform(test)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = process_df_for_spark_rf(train_raw, test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_spark_rf(train_df, test_df, n_trees=100):\n",
    "    rf = sparkRFClassifier(numTrees=n_trees)\n",
    "    rfModel = rf.fit(train_df)\n",
    "    pred_df = rfModel.transform(test_df)    \n",
    "    evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\n",
    "    auc = evaluator.evaluate(pred_df)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC for n = 1000: 0.61\n"
     ]
    }
   ],
   "source": [
    "auc = fit_spark_rf(train_df, test_df)\n",
    "print('Test AUC for n = 1000: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all together now, recording time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparkRF(n):\n",
    "    train_raw = get_data_spark_df(n=n)\n",
    "    train_df, test_df = process_df_for_spark_rf(train_raw, test_raw)\n",
    "    start = time.time()\n",
    "    auc = fit_spark_rf(train_df, test_df)\n",
    "    end = time.time()\n",
    "    return auc, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with n 1000\n",
      "Finished with n 10000\n",
      "Finished with n 100000\n",
      "Finished with n 1000000\n",
      "[0.6115738399618365, 0.6579431218508498, 0.6767651391054923, 0.6847054801281842]\n",
      "[26.75800085067749, 25.22200298309326, 28.198416709899902, 107.5358636379242]\n"
     ]
    }
   ],
   "source": [
    "sp_aucs = []\n",
    "sp_times = []\n",
    "ns =  [1e3, 1e4, 1e5, 1e6]\n",
    "for n in ns:\n",
    "    auc, t = sparkRF(n = n)\n",
    "    sp_aucs.append(auc)\n",
    "    sp_times.append(t)\n",
    "    print('Finished with n %d' % n)\n",
    "\n",
    "print(sp_aucs)\n",
    "print(sp_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_sklearn_df(n=None):\n",
    "    file_name = 'test' if n is None else 'train-' + str(n/1e6) + 'm'\n",
    "    pd_df = pd.read_csv('../air_example/' + file_name + '.csv', header = 0)\n",
    "    return pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = get_data_sklearn_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_for_sklearn_rf(train, test):\n",
    "    train_test = pd.concat([train, test])\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder.fit(train_test.iloc[:, :8])\n",
    "    X_train = encoder.transform(train.iloc[:, :8])\n",
    "    X_test = encoder.transform(test.iloc[:, :8])\n",
    "    y_train = train.iloc[:, 8]\n",
    "    y_test = test.iloc[:, 8]\n",
    "    return (X_train, y_train), (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_sklearn_rf(X_train, y_train, X_test, y_test, n_trees=100):\n",
    "    rf = sklearnRFClassifier(n_estimators=n_trees)\n",
    "    rfModel = rf.fit(X_train, y_train)\n",
    "    y_pred = rfModel.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearnRF(n):\n",
    "    train_raw = get_data_sklearn_df(n=n)\n",
    "    (X_train, y_train), (X_test, y_test) = process_df_for_sklearn_rf(train_raw, test_raw)\n",
    "    start = time.time()\n",
    "    auc = fit_sklearn_rf(X_train, y_train, X_test, y_test)\n",
    "    end = time.time()\n",
    "    return auc, end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with n 1000\n",
      "Finished with n 10000\n",
      "Finished with n 100000\n"
     ]
    }
   ],
   "source": [
    "sk_aucs = []\n",
    "sk_times = []\n",
    "ns =  [1e3, 1e4, 1e5, 1e6]\n",
    "for n in ns:\n",
    "    auc, t = sklearnRF(n = n)\n",
    "    sk_aucs.append(auc)\n",
    "    sk_times.append(t)\n",
    "    print('Finished with n %d' % n)\n",
    "\n",
    "print(sk_aucs)\n",
    "print(sk_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ns, sp_aucs, ns, sk_aucs)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Test AUC')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ns, sp_times, ns, sk_times)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('Time')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
